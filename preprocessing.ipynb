{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_baru_path = './dataset/dataset-testing/sentiment.sentiments-testing-new.csv'\n",
    "# data_baru_path = './dataset/indo-nlu-socialabs-merged-new-clean.csv'\n",
    "# data_baru_path = './dataset/dataset-penelitian/data_train_full_sentiment.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_csv(data_baru_path, sep=',', usecols=['label', 'text'])\n",
    "\n",
    "df = pd.read_csv(data_baru_path, sep=',', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = [\n",
    "#     \"@beautales_ @ohmybeautybank BENERRR MOIST COSRX INI GD YG NANDINGIN ALIAS AWETTT DAN BAGUS POL\",\n",
    "#     \"@nanawourld yg iniii pls bagus bgt! klo ga salah ada moistnya jg pengen beli tp moist cosrx aku belum abis setengah https://t.co/TvX4JAjGkc\",\n",
    "#     \"@ohmybeautybank kalo tekstur sih iyaa bisa tp aku ga yang gradakan bgt pake moist cosrx snail udh mulai baikann\",\n",
    "#     \"@beauthingy St aku normal to oily pake moist cosrx pedes di mata trus lama nyerep gtu gtau ga ccok di aku\",\n",
    "#     \"skincare koreanya ternyata emg sebagus itu ya baru make moist cosrx 2 minggu udh kerasa kulit muka lebih sehat\",\n",
    "#     \"@ohmybeautybank ini progress kulit aku setelah pemakaian moisturizer COSRX oil free selama 2 bulan. semoga kedepannya makin membaik skin type gatau bingung wkwk dulu kering sekarang berminyak acne prone? jujur gatau bedanya glowing sama berminyak https://t.co/Ju5Akg1jF\",\n",
    "        \"ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke\"\n",
    "#     \"@beautales_ pas paket moist cosrx punyaku dateng langsung aku pake dan DUAR paginya jerawat aku kering dan kempes semua terus tekstur kulit membaikk. sempet galau mau beli karna harganya yang agak mahal tapi pas uda beli ga menyesal sama sekali wehhh\",\n",
    "#     # \"@detikcom Ngurusin DKI Jakarta gak becus jadi menteri pendidikan dipecat pak Jokowi mau jadi presiden RI 2024 pula tu gak tau malu ni orang\",\n",
    "#     # \"@AREAJULID Zina dimana-mana, orang berpakaian seperti telanjang biasa aja. Giliran kasus ini bilang kalau palestina merdeka, kiamat. Aneh dah.\"\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data_test, columns=['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>conversation_id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id_str</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>username</th>\n",
       "      <th>projectId</th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>predicted_sentiment_cnn</th>\n",
       "      <th>predicted_sentiment_cnn_probability</th>\n",
       "      <th>predicted_sentiment_cnn_lstm</th>\n",
       "      <th>predicted_sentiment_cnn_lstm_probability</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66c31eb15d0c81cdd3de54dc</td>\n",
       "      <td>1750000000000000000</td>\n",
       "      <td>ganti moist Cosrx oil free malah beruntusan</td>\n",
       "      <td>1747645088002686976</td>\n",
       "      <td>https://x.com/13reason___/status/1747645088002...</td>\n",
       "      <td>1480000000000000000</td>\n",
       "      <td>13reason___</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.805551</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.555040</td>\n",
       "      <td>ganti memoist cosrx oil fre beruntus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66c31eb15d0c81cdd3de54d3</td>\n",
       "      <td>1750000000000000000</td>\n",
       "      <td>pengangguran lagi mikirin cara buat repurchase...</td>\n",
       "      <td>1746402502604374528</td>\n",
       "      <td>https://x.com/8sthetic_hao/status/174640250260...</td>\n",
       "      <td>758000000000000000</td>\n",
       "      <td>8sthetic_hao</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.914966</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.918385</td>\n",
       "      <td>angur pikir repurchase memoist cosrx bjir mome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66c31eb15d0c81cdd3de5453</td>\n",
       "      <td>1710000000000000000</td>\n",
       "      <td>Mending moist cosrx oil free atau snail? Aku b...</td>\n",
       "      <td>1708879699290755072</td>\n",
       "      <td>https://x.com/Astrophileguril/status/170887969...</td>\n",
       "      <td>1490000000000000000</td>\n",
       "      <td>Astrophileguril</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.743619</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.652787</td>\n",
       "      <td>mending memoist cosrx oil fre snail coba oil f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66c31eb15d0c81cdd3de552f</td>\n",
       "      <td>1770000000000000000</td>\n",
       "      <td>Gue keknya emang gak cocok dah ama tu moist co...</td>\n",
       "      <td>1769212395371774208</td>\n",
       "      <td>https://x.com/Horangiehae/status/1769212395371...</td>\n",
       "      <td>1440000000000000000</td>\n",
       "      <td>Horangiehae</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.994142</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.705369</td>\n",
       "      <td>gue kayak tidak_cocok deh memoist cosrx pakai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66c31eb15d0c81cdd3de560b</td>\n",
       "      <td>1790000000000000000</td>\n",
       "      <td>Ada yg pake skin1004 moist/cream nya gak sih? ...</td>\n",
       "      <td>1791515631659159808</td>\n",
       "      <td>https://x.com/Iv7/status/1791515631659159751</td>\n",
       "      <td>14472017</td>\n",
       "      <td>Iv7</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.859449</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.673033</td>\n",
       "      <td>pakai sk memoistcream tidak_review pakai memoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>66c31eb15d0c81cdd3de552e</td>\n",
       "      <td>1770000000000000000</td>\n",
       "      <td>@vaniaulia69 moist cosrx pump. maap hp nya ga ...</td>\n",
       "      <td>1769116160887578880</td>\n",
       "      <td>https://x.com/zoesyzh/status/1769116160887578804</td>\n",
       "      <td>1530000000000000000</td>\n",
       "      <td>zoesyzh</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831948</td>\n",
       "      <td>vaniaulia69</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.738851</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>memoist cosrx pump map hp tidak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>66c31eb15d0c81cdd3de55fc</td>\n",
       "      <td>1790000000000000000</td>\n",
       "      <td>@whutzeetoya Jokes aside focalskin bagus ga bu...</td>\n",
       "      <td>1785173420835295488</td>\n",
       "      <td>https://x.com/ouvertrue/status/178517342083529...</td>\n",
       "      <td>1370000000000000000</td>\n",
       "      <td>ouvertrue</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873640</td>\n",
       "      <td>whutzeetoya</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.878358</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.908610</td>\n",
       "      <td>jokes aside focalsk bagus tidak_jerawat pakai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>66c31eb15d0c81cdd3de55e4</td>\n",
       "      <td>1780000000000000000</td>\n",
       "      <td>@womanfeeds_id tolong yg akunnya gak gembokan ...</td>\n",
       "      <td>1777339840385974272</td>\n",
       "      <td>https://x.com/bangtarn/status/1777339840385974338</td>\n",
       "      <td>353981462</td>\n",
       "      <td>bangtarn</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958965</td>\n",
       "      <td>womanfeeds_id</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.819337</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.754973</td>\n",
       "      <td>id tolong a tidak_gembo sender memoist cosrx i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>66c31eb15d0c81cdd3de54c4</td>\n",
       "      <td>1740000000000000000</td>\n",
       "      <td>Tukang makeup kan udh bnyk spons foundi dipake...</td>\n",
       "      <td>1742021302351999232</td>\n",
       "      <td>https://x.com/yicchun/status/1742021302351999198</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>yicchun</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978406</td>\n",
       "      <td>yicchun</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.854330</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>0.668003</td>\n",
       "      <td>tukang memakeup spons found pakai ganti tidak_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>66c31eb15d0c81cdd3de5612</td>\n",
       "      <td>1790000000000000000</td>\n",
       "      <td>@yosefikr Bolehh moist cosrx birch oil free (m...</td>\n",
       "      <td>1793586383740936448</td>\n",
       "      <td>https://x.com/iniakunsambatje/status/179358638...</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>iniakunsambatje</td>\n",
       "      <td>66c31ea40ddfe332b967ef0f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964740</td>\n",
       "      <td>yosefikr</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.924122</td>\n",
       "      <td>Positif</td>\n",
       "      <td>0.968645</td>\n",
       "      <td>memoist cosrx birch oil fre memoist cosrx snai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id  conversation_id_str  \\\n",
       "0    66c31eb15d0c81cdd3de54dc  1750000000000000000   \n",
       "1    66c31eb15d0c81cdd3de54d3  1750000000000000000   \n",
       "2    66c31eb15d0c81cdd3de5453  1710000000000000000   \n",
       "3    66c31eb15d0c81cdd3de552f  1770000000000000000   \n",
       "4    66c31eb15d0c81cdd3de560b  1790000000000000000   \n",
       "..                        ...                  ...   \n",
       "452  66c31eb15d0c81cdd3de552e  1770000000000000000   \n",
       "453  66c31eb15d0c81cdd3de55fc  1790000000000000000   \n",
       "454  66c31eb15d0c81cdd3de55e4  1780000000000000000   \n",
       "455  66c31eb15d0c81cdd3de54c4  1740000000000000000   \n",
       "456  66c31eb15d0c81cdd3de5612  1790000000000000000   \n",
       "\n",
       "                                             full_text               id_str  \\\n",
       "0          ganti moist Cosrx oil free malah beruntusan  1747645088002686976   \n",
       "1    pengangguran lagi mikirin cara buat repurchase...  1746402502604374528   \n",
       "2    Mending moist cosrx oil free atau snail? Aku b...  1708879699290755072   \n",
       "3    Gue keknya emang gak cocok dah ama tu moist co...  1769212395371774208   \n",
       "4    Ada yg pake skin1004 moist/cream nya gak sih? ...  1791515631659159808   \n",
       "..                                                 ...                  ...   \n",
       "452  @vaniaulia69 moist cosrx pump. maap hp nya ga ...  1769116160887578880   \n",
       "453  @whutzeetoya Jokes aside focalskin bagus ga bu...  1785173420835295488   \n",
       "454  @womanfeeds_id tolong yg akunnya gak gembokan ...  1777339840385974272   \n",
       "455  Tukang makeup kan udh bnyk spons foundi dipake...  1742021302351999232   \n",
       "456  @yosefikr Bolehh moist cosrx birch oil free (m...  1793586383740936448   \n",
       "\n",
       "                                             tweet_url          user_id_str  \\\n",
       "0    https://x.com/13reason___/status/1747645088002...  1480000000000000000   \n",
       "1    https://x.com/8sthetic_hao/status/174640250260...   758000000000000000   \n",
       "2    https://x.com/Astrophileguril/status/170887969...  1490000000000000000   \n",
       "3    https://x.com/Horangiehae/status/1769212395371...  1440000000000000000   \n",
       "4         https://x.com/Iv7/status/1791515631659159751             14472017   \n",
       "..                                                 ...                  ...   \n",
       "452   https://x.com/zoesyzh/status/1769116160887578804  1530000000000000000   \n",
       "453  https://x.com/ouvertrue/status/178517342083529...  1370000000000000000   \n",
       "454  https://x.com/bangtarn/status/1777339840385974338            353981462   \n",
       "455   https://x.com/yicchun/status/1742021302351999198  1690000000000000000   \n",
       "456  https://x.com/iniakunsambatje/status/179358638...  1690000000000000000   \n",
       "\n",
       "            username                 projectId  topic  probability  \\\n",
       "0        13reason___  66c31ea40ddfe332b967ef0f      1     0.654915   \n",
       "1       8sthetic_hao  66c31ea40ddfe332b967ef0f      0     0.954144   \n",
       "2    Astrophileguril  66c31ea40ddfe332b967ef0f      0     0.515066   \n",
       "3        Horangiehae  66c31ea40ddfe332b967ef0f      1     0.976123   \n",
       "4                Iv7  66c31ea40ddfe332b967ef0f      1     0.978364   \n",
       "..               ...                       ...    ...          ...   \n",
       "452          zoesyzh  66c31ea40ddfe332b967ef0f      0     0.831948   \n",
       "453        ouvertrue  66c31ea40ddfe332b967ef0f      0     0.873640   \n",
       "454         bangtarn  66c31ea40ddfe332b967ef0f      1     0.958965   \n",
       "455          yicchun  66c31ea40ddfe332b967ef0f      0     0.978406   \n",
       "456  iniakunsambatje  66c31ea40ddfe332b967ef0f      0     0.964740   \n",
       "\n",
       "    in_reply_to_screen_name predicted_sentiment_cnn  \\\n",
       "0                       NaN                 Positif   \n",
       "1                       NaN                 Negatif   \n",
       "2                       NaN                 Positif   \n",
       "3                       NaN                 Negatif   \n",
       "4                       NaN                 Negatif   \n",
       "..                      ...                     ...   \n",
       "452             vaniaulia69                 Negatif   \n",
       "453             whutzeetoya                 Positif   \n",
       "454           womanfeeds_id                 Positif   \n",
       "455                 yicchun                 Negatif   \n",
       "456                yosefikr                 Positif   \n",
       "\n",
       "     predicted_sentiment_cnn_probability predicted_sentiment_cnn_lstm  \\\n",
       "0                               0.805551                      Positif   \n",
       "1                               0.914966                      Negatif   \n",
       "2                               0.743619                      Negatif   \n",
       "3                               0.994142                      Negatif   \n",
       "4                               0.859449                      Negatif   \n",
       "..                                   ...                          ...   \n",
       "452                             0.738851                      Negatif   \n",
       "453                             0.878358                      Positif   \n",
       "454                             0.819337                      Positif   \n",
       "455                             0.854330                      Negatif   \n",
       "456                             0.924122                      Positif   \n",
       "\n",
       "     predicted_sentiment_cnn_lstm_probability  \\\n",
       "0                                    0.555040   \n",
       "1                                    0.918385   \n",
       "2                                    0.652787   \n",
       "3                                    0.705369   \n",
       "4                                    0.673033   \n",
       "..                                        ...   \n",
       "452                                  0.813821   \n",
       "453                                  0.908610   \n",
       "454                                  0.754973   \n",
       "455                                  0.668003   \n",
       "456                                  0.968645   \n",
       "\n",
       "                                        processed_text  \n",
       "0                 ganti memoist cosrx oil fre beruntus  \n",
       "1    angur pikir repurchase memoist cosrx bjir mome...  \n",
       "2    mending memoist cosrx oil fre snail coba oil f...  \n",
       "3    gue kayak tidak_cocok deh memoist cosrx pakai ...  \n",
       "4    pakai sk memoistcream tidak_review pakai memoi...  \n",
       "..                                                 ...  \n",
       "452                    memoist cosrx pump map hp tidak  \n",
       "453  jokes aside focalsk bagus tidak_jerawat pakai ...  \n",
       "454  id tolong a tidak_gembo sender memoist cosrx i...  \n",
       "455  tukang memakeup spons found pakai ganti tidak_...  \n",
       "456  memoist cosrx birch oil fre memoist cosrx snai...  \n",
       "\n",
       "[457 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check duplicate data\n",
    "# print('Duplicate data:', df.duplicated().sum())\n",
    "\n",
    "# # remove duplicate data\n",
    "# df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## case folding kolom after\n",
    "df['processed'] = df['full_text'].str.lower()\n",
    "\n",
    "# df['processed'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke</td>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! kualitasnya oke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         full_text  \\\n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke   \n",
       "\n",
       "                                                                                                                                         processed  \n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! kualitasnya oke  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# ------ cleansing ---------\n",
    "\n",
    "\n",
    "def remove_tweet_special(text):\n",
    "    # remove tab, new line, ans back slice\n",
    "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "    # remove non ASCII (emoticon, chinese word, .etc)\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    # remove mention, link, hashtag\n",
    "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "    # remove incomplete URL\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "\n",
    "df[\"processed\"] = df[\"processed\"].apply(remove_tweet_special)      \n",
    "# df_train[\"processed\"] = df_train[\"processed\"].apply(remove_tweet_special)\n",
    "# df_valid[\"processed\"] = df_valid[\"processed\"].apply(remove_tweet_special)\n",
    "# df_test[\"processed\"] = df_test[\"processed\"].apply(remove_tweet_special)\n",
    " \n",
    "\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "df['processed'] = df['processed'].apply(remove_number)\n",
    "# df_train['processed'] = df_train['processed'].apply(remove_number)\n",
    "# df_valid['processed'] = df_valid['processed'].apply(remove_number)\n",
    "# df_test['processed'] = df_test['processed'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "df['processed'] = df['processed'].apply(remove_punctuation)\n",
    "# df_train['processed'] = df_train['processed'].apply(remove_punctuation)\n",
    "# df_valid['processed'] = df_valid['processed'].apply(remove_punctuation)\n",
    "# df_test['processed'] = df_test['processed'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "df['processed'] = df['processed'].apply(remove_whitespace_LT)\n",
    "# df_train['processed'] = df_train['processed'].apply(remove_whitespace_LT)\n",
    "# df_valid['processed'] = df_valid['processed'].apply(remove_whitespace_LT)\n",
    "# df_test['processed'] = df_test['processed'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "df['processed'] = df['processed'].apply(remove_whitespace_multiple)\n",
    "# df_train['processed'] = df_train['processed'].apply(remove_whitespace_multiple)\n",
    "# df_valid['processed'] = df_valid['processed'].apply(remove_whitespace_multiple)\n",
    "# df_test['processed'] = df_test['processed'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "df['processed'] = df['processed'].apply(remove_singl_char)\n",
    "\n",
    "# Mengurangi pengulangan karakter yang berlebihan dalam teks \n",
    "def remove_repeated_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "df['processed'] = df['processed'].apply(remove_repeated_char)\n",
    "# df_train['processed'] = df_train['processed'].apply(remove_singl_char)\n",
    "# df_valid['processed'] = df_valid['processed'].apply(remove_singl_char)\n",
    "# df_test['processed'] = df_test['processed'].apply(remove_singl_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke</td>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan dan yang terpenting tidak bikin saya jerawatan wangi kualitasnya oke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         full_text  \\\n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke   \n",
       "\n",
       "                                                                                                                                    processed  \n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan dan yang terpenting tidak bikin saya jerawatan wangi kualitasnya oke  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# df[\"before\"] = df[\"after\"]\n",
    "df['processed'] = df['processed'].apply(word_tokenize_wrapper)\n",
    "# df_train['processed'] = df_train['processed'].apply(word_tokenize_wrapper)\n",
    "# df_valid['processed'] = df_valid['processed'].apply(word_tokenize_wrapper)\n",
    "# df_test['processed'] = df_test['processed'].apply(word_tokenize_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke</td>\n",
       "      <td>[ini, toner, andalan, saya, yang, saya, suka, adalah, formulanya, sangat, ringan, dan, yang, terpenting, tidak, bikin, saya, jerawatan, wangi, kualitasnya, oke]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         full_text  \\\n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke   \n",
       "\n",
       "                                                                                                                                                          processed  \n",
       "0  [ini, toner, andalan, saya, yang, saya, suka, adalah, formulanya, sangat, ringan, dan, yang, terpenting, tidak, bikin, saya, jerawatan, wangi, kualitasnya, oke]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_4236\\2511250632.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[0] not in normalizad_word_dict:\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_4236\\2511250632.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  normalizad_word_dict[row[0]] = row[1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke</td>\n",
       "      <td>[ini, toner, andalan, saya, yang, saya, suka, adalah, formulanya, sangat, ringan, dan, yang, terpenting, tidak, bikin, saya, jerawatan, wangi, kualitasnya, oke]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         full_text  \\\n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke   \n",
       "\n",
       "                                                                                                                                                          processed  \n",
       "0  [ini, toner, andalan, saya, yang, saya, suka, adalah, formulanya, sangat, ringan, dan, yang, terpenting, tidak, bikin, saya, jerawatan, wangi, kualitasnya, oke]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## normalization\n",
    "\n",
    "normalizad_word = pd.read_csv(\"./utils/kamus-alay.csv\")\n",
    "\n",
    "normalizad_word_dict = {}\n",
    "\n",
    "for index, row in normalizad_word.iterrows():\n",
    "    if row[0] not in normalizad_word_dict:\n",
    "        normalizad_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "\n",
    "# df[\"before\"] = df[\"after\"]\n",
    "df['processed'] = df['processed'].apply(normalized_term)\n",
    "# df_train['processed'] = df_train['processed'].apply(normalized_term)\n",
    "# df_valid['processed'] = df_valid['processed'].apply(normalized_term)\n",
    "# df_test['processed'] = df_test['processed'].apply(normalized_term)\n",
    "\n",
    "df\n",
    "# df_train\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpstemmer import MPStemmer\n",
    "\n",
    "stemmer = MPStemmer()\n",
    "\n",
    "\n",
    "def stemmed_wrapper(term):\n",
    "    return [stemmer.stem(word) for word in term]\n",
    "\n",
    "# df[\"before\"] = df[\"after\"]\n",
    "df['processed'] = df['processed'].apply(stemmed_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke</td>\n",
       "      <td>[ini, toner, andal, saya, yang, saya, suka, adalah, formula, sangat, ringan, dan, yang, penting, tidak, bikin, saya, jerawat, wangi, kualitas, oke]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         full_text  \\\n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke   \n",
       "\n",
       "                                                                                                                                             processed  \n",
       "0  [ini, toner, andal, saya, yang, saya, suka, adalah, formula, sangat, ringan, dan, yang, penting, tidak, bikin, saya, jerawat, wangi, kualitas, oke]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke</td>\n",
       "      <td>[toner, andal, suka, formula, ringan, tidak, jerawat, wangi, kualitas, oke]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         full_text  \\\n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke   \n",
       "\n",
       "                                                                     processed  \n",
       "0  [toner, andal, suka, formula, ringan, tidak, jerawat, wangi, kualitas, oke]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## stopword removal\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('indonesian')\n",
    "\n",
    "# Hapus kata \"tidak\" dari daftar stopword\n",
    "stop_words = [word for word in stop_words if word not in ['tidak', 'baik', 'jelek', 'jangan', 'belum', 'bukan', \"enggak\", \"engga\", \"bener\", \"benar\"]]\n",
    "\n",
    "# ---------------------------- manualy add stopword  ------------------------------------\n",
    "# append additional stopword\n",
    "stop_words.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', \n",
    "                       'kalo', 'amp', 'biar', 'bikin', 'bilang', \n",
    "                       'gak', 'ga', 'krn', 'nya', 'nih', 'sih', \n",
    "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', \n",
    "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't', \n",
    "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
    "                       '&amp', 'yah'])\n",
    "\n",
    "# ----------------------- add stopword from txt file ------------------------------------\n",
    "# read txt stopword using pandas\n",
    "txt_stopword = pd.read_csv(\"./utils/stopwords.txt\", names= [\"stopwords\"], header = None)\n",
    "\n",
    "# convert stopword string to list & append additional stopword\n",
    "stop_words.extend(txt_stopword[\"stopwords\"][0].split(' '))\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "# convert list to dictionary\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "\n",
    "#remove stopword pada list token\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "\n",
    "# df[\"before\"] = df[\"after\"]\n",
    "df['processed'] = df['processed'].apply(stopwords_removal)\n",
    "# df_train['processed'] = df_train['processed'].apply(stopwords_removal)\n",
    "# df_valid['processed'] = df_valid['processed'].apply(stopwords_removal)\n",
    "# df_test['processed'] = df_test['processed'].apply(stopwords_removal)\n",
    "\n",
    "df\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./dataset/indo-nlu-socialabs-merged-new-clean-tanpa-negasi.csv', index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stop_word = pd.DataFrame(stop_words, columns=['stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stop_word.to_csv(\"./utils/stopwords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_negation(tokens):\n",
    "    negations = {'tidak', 'jangan', 'belum', 'bukan', 'enggak'}\n",
    "    result = []\n",
    "    skip_next = False\n",
    "\n",
    "    for i, word in enumerate(tokens):\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "        if word in negations and i + 1 < len(tokens):\n",
    "            next_word = tokens[i + 1]\n",
    "            result.append(f'{word}_{next_word}')\n",
    "            skip_next = True\n",
    "        else:\n",
    "            result.append(word)\n",
    "\n",
    "    return result\n",
    "\n",
    "df['processed'] = df['processed'].apply(convert_negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke</td>\n",
       "      <td>[toner, andal, suka, formula, ringan, tidak_jerawat, wangi, kualitas, oke]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         full_text  \\\n",
       "0  ini toner andalan saya yang saya suka adalah formulanya sangat ringan, dan yang terpenting tidak bikin saya jerawatan :) wangi! Kualitasnya oke   \n",
       "\n",
       "                                                                    processed  \n",
       "0  [toner, andal, suka, formula, ringan, tidak_jerawat, wangi, kualitas, oke]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('./dataset/dataset-testing/moist-cosrx-clean.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./dataset/indo-nlu-socialabs-merged-new-clean.csv', index=False, sep=',')\n",
    "# df.to_csv('./dataset/dataset-penelitian/data_train_full_sentiment_clean.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleksi atribut full_text, topic, dan processed\n",
    "df = df[['full_text', 'topic','processed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_testing_preprocessed = df\n",
    "data_testing_preprocessed.to_csv('./dataset/dataset-testing/testing-new-preprocessed.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
